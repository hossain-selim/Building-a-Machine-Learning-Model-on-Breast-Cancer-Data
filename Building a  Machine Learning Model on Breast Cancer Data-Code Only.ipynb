{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f49f33",
   "metadata": {},
   "source": [
    "Define Problem Statement\n",
    "\n",
    "Our objective is to identify which features are most helpful in predicting malignant or benign cancer and to classify whether the breast cancer is benign or malignant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c4f5340",
   "metadata": {},
   "source": [
    "Data Source: \n",
    "Extracted from - https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a89d718",
   "metadata": {},
   "source": [
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. ID number\n",
    "2. Diagnosis (M = malignant, B = benign) Columns 3 to 32\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "c) perimeter\n",
    "d) area\n",
    "e) smoothness (local variation in radius lengths)\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "h) concave points (number of concave portions of the contour)\n",
    "i) symmetry \n",
    "j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2dfe35",
   "metadata": {},
   "source": [
    "Data Cleaning and Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Importing dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "X = df.iloc[:, 1:31].values\n",
    "Y = df.iloc[:, 31].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf996ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataset\n",
    "print(\"Cancer data set dimensions : {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_counts = df['diagnosis'].value_counts()\n",
    "\n",
    "# Print the counts for 'M' and 'B' separately\n",
    "count_M = diagnosis_counts['M']\n",
    "count_B = diagnosis_counts['B']\n",
    "\n",
    "print(f'Count of M: {count_M}')\n",
    "print(f'Count of B: {count_B}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aa70df6",
   "metadata": {},
   "source": [
    "Our response variable, diagnosis, is categorical and has two classes, 'B' (Benign) and 'M' (Malignant). All explanatory variables are numerical, so we can skip data type conversion.\n",
    "\n",
    "Let's now take a closer look at our response variable, since it is the main focus of our analysis. We begin by checking out the distribution of its classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf38b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize distribution of classes\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=df, x='diagnosis', palette='RdBu')\n",
    "\n",
    "# Count the number of observations in each class\n",
    "benign, malignant = df['diagnosis'].value_counts()\n",
    "print('Number of cells labeled Benign: ', benign)\n",
    "print('Number of cells labeled Malignant : ', malignant)\n",
    "print('')\n",
    "print('% of cells labeled Benign', round(benign / len(df) * 100, 2), '%')\n",
    "print('% of cells labeled Malignant', round(malignant / len(df) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f22ca3b",
   "metadata": {},
   "source": [
    "Out of the 569 observations, 357 (or 62.7%) have been labeled malignant, while the rest 212 (or 37.3%) have been labeled benign. Later when we develop a predictive model and test it on unseen data, we should expect to see a similar proportion of labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb787d",
   "metadata": {},
   "source": [
    "Let's quickly scan for any interesting patterns between our 10 \"mean\" columns and the response variable by generating a scatter plot matrix as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5231842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Scatter Plot matrix with the \"mean\" columns\n",
    "cols = ['diagnosis',\n",
    "        'radius_mean', \n",
    "        'texture_mean', \n",
    "        'perimeter_mean', \n",
    "        'area_mean', \n",
    "        'smoothness_mean', \n",
    "        'compactness_mean', \n",
    "        'concavity_mean',\n",
    "        'concave points_mean', \n",
    "        'symmetry_mean', \n",
    "        'fractal_dimension_mean']\n",
    "\n",
    "sns.pairplot(data=df[cols], hue='diagnosis', palette='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22499dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50853d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Impute missing values with the mean value\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data values\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa100a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable 'diagnosis'\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(df['diagnosis'])\n",
    "\n",
    "# Create a copy of your original dataframe for preprocessing\n",
    "X_encoded = df.copy()\n",
    "\n",
    "# Drop non-numeric columns\n",
    "# Drop 'id' and 'Unnamed: 32'\n",
    "non_numeric_cols = ['id', 'Unnamed: 32']\n",
    "X_encoded.drop(non_numeric_cols, axis=1, inplace=True)\n",
    "\n",
    "# Split the dataset into the Training set and Test set\n",
    "X = X_encoded.drop(columns=['diagnosis'])  # Remove the target variable\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f88e83",
   "metadata": {},
   "source": [
    "The Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f21415a",
   "metadata": {},
   "source": [
    "As this is a classification problem so we will use following models to predict our target variable -\n",
    "1. Logistic Regression\n",
    "2. KNN\n",
    "3. SVM\n",
    "4. Naive Bayes\n",
    "5. Decision Tree\n",
    "6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f5d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "# Create and fit the Logistic Regression model\n",
    "logistic_model = LogisticRegression(random_state=0)\n",
    "logistic_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_logistic = confusion_matrix(Y_test, Y_pred_logistic)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TN_logistic = confusion_logistic[0, 0]\n",
    "FP_logistic = confusion_logistic[0, 1]\n",
    "FN_logistic = confusion_logistic[1, 0]\n",
    "TP_logistic = confusion_logistic[1, 1]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_logistic = (TP_logistic + TN_logistic) / (TP_logistic + TN_logistic + FP_logistic + FN_logistic) * 100\n",
    "\n",
    "# Print the model name\n",
    "print(\"Model: Logistic Regression\")\n",
    "\n",
    "# Print classification report\n",
    "report_logistic = classification_report(Y_test, Y_pred_logistic)\n",
    "print(\"Classification Report:\\n\", report_logistic)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_logistic)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Negative: {TN_logistic}\")\n",
    "print(f\"False Positive: {FP_logistic}\")\n",
    "print(f\"False Negative: {FN_logistic}\")\n",
    "print(f\"True Positive: {TP_logistic}\")\n",
    "print(f\"Correct Predictions: {accuracy_logistic:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60982265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Model\n",
    "\n",
    "# Create and fit the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "knn_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_knn = confusion_matrix(Y_test, Y_pred_knn)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TN_knn = confusion_knn[0, 0]\n",
    "FP_knn = confusion_knn[0, 1]\n",
    "FN_knn = confusion_knn[1, 0]\n",
    "TP_knn = confusion_knn[1, 1]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_knn = (TP_knn + TN_knn) / (TP_knn + TN_knn + FP_knn + FN_knn) * 100\n",
    "\n",
    "# Print the model name\n",
    "print(\"Model: K-Nearest Neighbors\")\n",
    "\n",
    "# Print classification report\n",
    "report_knn = classification_report(Y_test, Y_pred_knn)\n",
    "print(\"Classification Report:\\n\", report_knn)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_knn)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Negative: {TN_knn}\")\n",
    "print(f\"False Positive: {FP_knn}\")\n",
    "print(f\"False Negative: {FN_knn}\")\n",
    "print(f\"True Positive: {TP_knn}\")\n",
    "print(f\"Correct Predictions: {accuracy_knn:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76743a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Model\n",
    "\n",
    "# Create and fit the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=0)\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_svm = confusion_matrix(Y_test, Y_pred_svm)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TN_svm = confusion_svm[0, 0]\n",
    "FP_svm = confusion_svm[0, 1]\n",
    "FN_svm = confusion_svm[1, 0]\n",
    "TP_svm = confusion_svm[1, 1]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_svm = (TP_svm + TN_svm) / (TP_svm + TN_svm + FP_svm + FN_svm) * 100\n",
    "\n",
    "# Print the model name\n",
    "print(\"Model: Support Vector Machine\")\n",
    "\n",
    "# Print classification report\n",
    "report_svm = classification_report(Y_test, Y_pred_svm)\n",
    "print(\"Classification Report:\\n\", report_svm)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_svm)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Negative: {TN_svm}\")\n",
    "print(f\"False Positive: {FP_svm}\")\n",
    "print(f\"False Negative: {FN_svm}\")\n",
    "print(f\"True Positive: {TP_svm}\")\n",
    "print(f\"Correct Predictions: {accuracy_svm:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068656a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Model\n",
    "\n",
    "# Create and fit the Naïve Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_nb = confusion_matrix(Y_test, Y_pred_nb)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TN_nb = confusion_nb[0, 0]\n",
    "FP_nb = confusion_nb[0, 1]\n",
    "FN_nb = confusion_nb[1, 0]\n",
    "TP_nb = confusion_nb[1, 1]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_nb = (TP_nb + TN_nb) / (TP_nb + TN_nb + FP_nb + FN_nb) * 100\n",
    "\n",
    "# Print the model name\n",
    "print(\"Model: Naïve Bayes\")\n",
    "\n",
    "# Print classification report\n",
    "report_nb = classification_report(Y_test, Y_pred_nb)\n",
    "print(\"Classification Report:\\n\", report_nb)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_nb)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Negative: {TN_nb}\")\n",
    "print(f\"False Positive: {FP_nb}\")\n",
    "print(f\"False Negative: {FN_nb}\")\n",
    "print(f\"True Positive: {TP_nb}\")\n",
    "print(f\"Correct Predictions: {accuracy_nb:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a711c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Model\n",
    "\n",
    "# Create and fit the Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "dt_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_dt = confusion_matrix(Y_test, Y_pred_dt)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TN_dt = confusion_dt[0, 0]\n",
    "FP_dt = confusion_dt[0, 1]\n",
    "FN_dt = confusion_dt[1, 0]\n",
    "TP_dt = confusion_dt[1, 1]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_dt = (TP_dt + TN_dt) / (TP_dt + TN_dt + FP_dt + FN_dt) * 100\n",
    "\n",
    "# Print the model name\n",
    "print(\"Model: Decision Tree\")\n",
    "\n",
    "# Print classification report\n",
    "report_dt = classification_report(Y_test, Y_pred_dt)\n",
    "print(\"Classification Report:\\n\", report_dt)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_dt)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Negative: {TN_dt}\")\n",
    "print(f\"False Positive: {FP_dt}\")\n",
    "print(f\"False Negative: {FN_dt}\")\n",
    "print(f\"True Positive: {TP_dt}\")\n",
    "print(f\"Correct Predictions: {accuracy_dt:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d376e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "# Create and fit the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_rf = confusion_matrix(Y_test, Y_pred_rf)\n",
    "\n",
    "# Extract TP, TN, FP, FN from the confusion matrix\n",
    "TN_rf = confusion_rf[0, 0]\n",
    "FP_rf = confusion_rf[0, 1]\n",
    "FN_rf = confusion_rf[1, 0]\n",
    "TP_rf = confusion_rf[1, 1]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rf = (TP_rf + TN_rf) / (TP_rf + TN_rf + FP_rf + FN_rf) * 100\n",
    "\n",
    "# Print the model name\n",
    "print(\"Model: Random Forest\")\n",
    "\n",
    "# Print classification report\n",
    "report_rf = classification_report(Y_test, Y_pred_rf)\n",
    "print(\"Classification Report:\\n\", report_rf)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_rf)\n",
    "\n",
    "# Print additional metrics\n",
    "print(f\"True Negative: {TN_rf}\")\n",
    "print(f\"False Positive: {FP_rf}\")\n",
    "print(f\"False Negative: {FN_rf}\")\n",
    "print(f\"True Positive: {TP_rf}\")\n",
    "print(f\"Correct Predictions: {accuracy_rf:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7105e42",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3063238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing All Models\n",
    "\n",
    "# Create and initialize the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=0),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2),\n",
    "    \"Support Vector Machine (Linear)\": SVC(kernel='linear', random_state=0),\n",
    "    \"Support Vector Machine (RBF)\": SVC(kernel='rbf', random_state=0),\n",
    "    \"Naïve Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion='entropy', random_state=0),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "}\n",
    "\n",
    "# Initialize an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    confusion = confusion_matrix(Y_test, Y_pred)\n",
    "    TN = confusion[0, 0]\n",
    "    FP = confusion[0, 1]\n",
    "    FN = confusion[1, 0]\n",
    "    TP = confusion[1, 1]\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) * 100\n",
    "    results[model_name] = accuracy\n",
    "\n",
    "results_df = pd.DataFrame(results.items(), columns=['Model', 'Accuracy'])\n",
    "results_df.set_index('Model', inplace=True)\n",
    "\n",
    "# Sort the results by accuracy in descending order\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "# Display the comparison table\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e7228e0",
   "metadata": {},
   "source": [
    "From above table we can see that Random Forest Classification algorithm gives the best results for our dataset with the Correct Predictions: 98.60%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
